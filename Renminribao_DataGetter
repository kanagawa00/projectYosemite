from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.wait import WebDriverWait
import time,re,requests
import pandas as pd

search_keyword="机器学习"
################################################
#検索
browser = webdriver.Chrome()
browser.get("http://data.people.com.cn/rmrb/")
browser.find_element_by_name("queryStr").send_keys(search_keyword)
browser.find_element_by_class_name("search_btn").click()
browser.find_element_by_id("searchInAll").click()
browser.find_element_by_xpath('//*[@class="sortUl_li"and@value="1"]').click()
time.sleep(1)
################################################
filenum="0000"
articles=[]

def onepage(browser,start,pdlist):
    linklist=[]
    for link in browser.find_elements_by_xpath('//*[@class="open_detail_link"]'):
        #htmldata=requests.get(link.get_attribute("href")).text
        getlink=link.get_attribute("href")
        linklist.append(getlink)
    for truelink in linklist:
        onettl,onedetail,oneset=getdetail(browser,truelink)        
        fn=start
        f=open("C:\\Users\\Shuai\\Desktop\\Renminribao\\"+fn+".txt","w",encoding="utf-8")
        f.write("<title>"+onettl+"</title>")
        f.write("\n")
        f.write(onedetail)
        f.close()
        pdlist.append(oneset)
        start=str("%04d" % (int(start)+1))
        time.sleep(1)
    try:
        browser.find_element_by_xpath('//*[@title="下一页"]').click()
    except:
        pass
    return start

def getdetail(browser,url):
    #url.click()
    #browser.switch_to_window(browser.window_handles[1])
    browser.get(url)
    ttl=browser.find_element_by_class_name("title").text
    left=browser.find_element_by_class_name("sha_left").text
    date=re.search(r"(?<=人民日报)\d{4}年\d{1,2}月\d{1,2}日",left).group()
    area=re.search(r"第\d{1,2}版",left).group()
    detail=browser.find_element_by_class_name("detail_con").text
    #print(ttl)
    #print(detail)
    browser.back()
    return ttl,detail,[ttl,date,area]

#ページの切り替え
w_start=1
w_news=browser.find_element_by_xpath('//*[@id="allDataCount"]')
w_page=int(w_news.text)//20+1
while w_start<=w_page:
    filenum=onepage(browser,filenum,articles)
    w_start+=1
    
browser.quit()

df = pd.DataFrame(articles,columns=["タイトル","時間","版"])
df.to_csv("Renminribao2.csv",encoding="utf-8",sep="\t", index=False)
print(df)

import matplotlib.pyplot as plt

x=[]
y=[]
for n in range(1949,2019):
    year=df["時間"].str.startswith(str(n)).sum()
    x.append(n)
    y.append(year)
    #print(n,"年：",year,"件")
###########################################################
plt.figure(figsize=(10,4))
plt.plot(x,y,color="red", linewidth=3.0, linestyle="--")
plt.xticks(fontsize=15)
plt.yticks(fontsize=15) 
font ={"family":"SimHei","weight":"normal","size":15}
plt.title("図1　人民日報におけるタイトルに人工知能が含まれる報道の経時的な推移",font)
plt.xlabel("年",font)
plt.ylabel("件数",font)
plt.show()
##########################################################
